{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the dc.tif file and the original Virginia Beach GeoTIFF file\n",
    "with rasterio.open(dc_tif_path) as dc_src, rasterio.open(vb_tif_path) as vb_src:\n",
    "    # Read the metadata of each image\n",
    "    dc_metadata = dc_src.meta\n",
    "    vb_metadata = vb_src.meta\n",
    "    \n",
    "    # Update the Virginia Beach metadata to match DC metadata, except for width, height, and count\n",
    "    vb_metadata.update({\n",
    "        key: value for key, value in dc_metadata.items() if key not in ['width', 'height', 'count']\n",
    "    })\n",
    "    \n",
    "    # Save the updated Virginia Beach GeoTIFF file with the new metadata\n",
    "    with rasterio.open(\n",
    "        updated_vb_tif_path,\n",
    "        'w',\n",
    "        **vb_metadata\n",
    "    ) as dst:\n",
    "        for i in range(1, vb_src.count + 1):\n",
    "            dst.write(vb_src.read(i), i)\n",
    "    \n",
    "    # Plot the metadata of each image side by side\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
    "    \n",
    "    axes[0].imshow(dc_src.read(1), cmap='gray')\n",
    "    axes[0].set_title('First Band of DC GeoTIFF Image')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(vb_src.read(1), cmap='gray')\n",
    "    axes[1].set_title('First Band of Virginia Beach GeoTIFF Image')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Print metadata\n",
    "    print(\"DC GeoTIFF Metadata:\")\n",
    "    for key, value in dc_metadata.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    print(\"\\nVirginia Beach GeoTIFF Metadata (Updated):\")\n",
    "    for key, value in vb_metadata.items():\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- Common colormaps include: 'viridis', 'plasma', 'inferno', 'magma', 'cividis', 'gray', 'hot', 'cool', 'spring', 'summer', 'autumn', 'winter'.\n",
    "\"\"\"\n",
    "def plot_hyperspectral_images_with_keys(path, keys, band=0):\n",
    "    # Load the .mat file\n",
    "    data = scipy.io.loadmat(path)\n",
    "    \n",
    "    # Extract the 3D arrays using the provided keys\n",
    "    arrays = [data[key] for key in keys]\n",
    "    \n",
    "    # Extract the specified band (assuming the third dimension is the spectral dimension)\n",
    "    bands = [array[:, :, band] for array in arrays]\n",
    "    \n",
    "    # Plot the images side by side\n",
    "    fig, axes = plt.subplots(1, len(bands), figsize=(15, 5))\n",
    "    \n",
    "    for ax, band, key in zip(axes, bands, keys):\n",
    "        ax.imshow(band, cmap='viridis')\n",
    "        ax.imshow(band, cmap='viridis', alpha=0)\n",
    "        ax.set_title(f'{key}')\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "plot_hyperspectral_images_with_keys(\n",
    "    './data/HSI_Data/Hyperspectral_Project/WDC/results/hypersigma/hypersigma_Case5.mat',\n",
    "    keys=['gt', 'input', 'output'],\n",
    "    band=60  # Change this value to plot a different band\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of WDC case data: (191, 192, 192)\n",
      "Shape of HYPSO case data: (120, 192, 192)\n"
     ]
    }
   ],
   "source": [
    "wdc_test = './data/HSI_Data/Hyperspectral_Project/WDC/test/test.mat'\n",
    "hypso_test = './data/HSI_Data/Hyperspectral_Project/HYPSO/test/test.mat'\n",
    "wdc_test_case='./data/HSI_Data/Hyperspectral_Project/WDC/test_noise/Cases/Case2/test.mat'\n",
    "hypso_test_case='./data/HSI_Data/Hyperspectral_Project/HYPSO/test_noise/Cases/Case2/test.mat'\n",
    "# Load the .mat files\n",
    "wdc_data = scipy.io.loadmat(wdc_test)\n",
    "hypso_data = scipy.io.loadmat(hypso_test)\n",
    "wdc_case_data = scipy.io.loadmat(wdc_test_case)\n",
    "hypso_case_data = scipy.io.loadmat(hypso_test_case)\n",
    "\n",
    "# BEGIN: shape of wdc case data and hypso case data\n",
    "wdc_case_shape = wdc_case_data['gt'].shape\n",
    "hypso_case_shape = hypso_case_data['gt'].shape\n",
    "\n",
    "print(\"Shape of WDC case data:\", wdc_case_shape)\n",
    "print(\"Shape of HYPSO case data:\", hypso_case_shape)\n",
    "# END:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create wdc...\n",
    "Map size(GB): 0.23591503500938416\n",
    "loading mat: train_0.mat\n",
    "-------------------\n",
    "Preprocessing data...\n",
    "Preprocess data shape: (191, 600, 307)\n",
    "zooming to 1.000000\n",
    "zooming to 0.500000\n",
    "zooming to 0.250000\n",
    "new data 0 shape  (544, 191, 64, 64)\n",
    "new data 1 shape  (360, 191, 64, 64)\n",
    "new data 2 shape  (22, 191, 64, 64)\n",
    "concatenating data...\n",
    "new data shape after conc: (926, 191, 64, 64)\n",
    "augmenting data...\n",
    "Postprocess data shape: (926, 191, 64, 64)\n",
    "/home/lofty/CODE/HyperSIGMA-fork/ImageDenoising/data/HSI_Data/Hyperspectral_Project/WDC/wdc.db\n",
    "load mat: train_0.mat\n",
    "-------------------\n",
    "Preprocessing data...\n",
    "Preprocess data shape: (191, 600, 307)\n",
    "zooming to 1.000000\n",
    "zooming to 0.500000\n",
    "zooming to 0.250000\n",
    "new data 0 shape  (544, 191, 64, 64)\n",
    "new data 1 shape  (360, 191, 64, 64)\n",
    "new data 2 shape  (22, 191, 64, 64)\n",
    "concatenating data...\n",
    "new data shape after conc: (926, 191, 64, 64)\n",
    "augmenting data...\n",
    "Postprocess data shape: (926, 191, 64, 64)\n",
    "load mat: train_1.mat\n",
    "-------------------\n",
    "Preprocessing data...\n",
    "Preprocess data shape: (191, 480, 307)\n",
    "zooming to 1.000000\n",
    "zooming to 0.500000\n",
    "zooming to 0.250000\n",
    "new data 0 shape  (432, 191, 64, 64)\n",
    "new data 1 shape  (276, 191, 64, 64)\n",
    "new data 2 shape  (16, 191, 64, 64)\n",
    "concatenating data...\n",
    "new data shape after conc: (724, 191, 64, 64)\n",
    "augmenting data...\n",
    "Postprocess data shape: (724, 191, 64, 64)\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create HYPSO...\n",
    "Map size(GB): 0.15870451927185059\n",
    "loading mat: train_0.mat\n",
    "-------------------\n",
    "Preprocessing data...\n",
    "Preprocess data shape: (120, 600, 398)\n",
    "zooming to 1.000000\n",
    "zooming to 0.500000\n",
    "zooming to 0.250000\n",
    "new data 0 shape  (714, 120, 64, 64)\n",
    "new data 1 shape  (510, 120, 64, 64)\n",
    "new data 2 shape  (55, 120, 64, 64)\n",
    "concatenating data...\n",
    "new data shape after conc: (1279, 120, 64, 64)\n",
    "augmenting data...\n",
    "Postprocess data shape: (1279, 120, 64, 64)\n",
    "/home/lofty/CODE/HyperSIGMA-fork/ImageDenoising/data/HSI_Data/Hyperspectral_Project/HYPSO2/hypso.db\n",
    "load mat: train_0.mat\n",
    "-------------------\n",
    "Preprocessing data...\n",
    "Preprocess data shape: (120, 600, 398)\n",
    "zooming to 1.000000\n",
    "zooming to 0.500000\n",
    "zooming to 0.250000\n",
    "new data 0 shape  (714, 120, 64, 64)\n",
    "new data 1 shape  (510, 120, 64, 64)\n",
    "new data 2 shape  (55, 120, 64, 64)\n",
    "concatenating data...\n",
    "new data shape after conc: (1279, 120, 64, 64)\n",
    "augmenting data...\n",
    "Postprocess data shape: (1279, 120, 64, 64)\n",
    "load mat: train_1.mat\n",
    "-------------------\n",
    "Preprocessing data...\n",
    "Preprocess data shape: (120, 292, 398)\n",
    "zooming to 1.000000\n",
    "zooming to 0.500000\n",
    "zooming to 0.250000\n",
    "new data 0 shape  (315, 120, 64, 64)\n",
    "new data 1 shape  (187, 120, 64, 64)\n",
    "new data 2 shape  (10, 120, 64, 64)\n",
    "concatenating data...\n",
    "new data shape after conc: (512, 120, 64, 64)\n",
    "augmenting data...\n",
    "Postprocess data shape: (512, 120, 64, 64)\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Namespace(\n",
    "    prefix='hypersigma_gaussian', \n",
    "    arch='hypersigma', \n",
    "    batchSize=16, \n",
    "    lr=0.0001, \n",
    "    wd=0, \n",
    "    loss='l2', \n",
    "    testdir='./data/HSI_Data/Hyperspectral_Project/HYPSO2/test_noise/Patch_Cases/Case5', \n",
    "    sigma=None, \n",
    "    training_dataset_path='/home/lofty/CODE/HyperSIGMA-fork/ImageDenoising/data/HSI_Data/Hyperspectral_Project/WDC/wdc_64.db', \n",
    "    pretrain='/home/lofty/CODE/HyperSIGMA-fork/ImageDenoising/pre_train/checkpoint-400.pth', \n",
    "    init='kn', \n",
    "    no_cuda=False, \n",
    "    from_scratch=False, \n",
    "    pretrain_path='/home/lofty/CODE/HyperSIGMA-fork/spat-base.pth', \n",
    "    no_log=False, \n",
    "    threads=1, \n",
    "    seed=2018, \n",
    "    resume=True, \n",
    "    no_ropt=False, \n",
    "    chop=False, \n",
    "    resumePath='./output/original_hypersigma_1e-4_spat-base_batch4_warmup_l2_epoch_1_complex_s3_8point_HYPSO2/hypersigma_gaussian/model_latest.pth', \n",
    "    dataroot='/data/HSI_Data/ICVL64_31.db', \n",
    "    clip=1000000.0, \n",
    "    gpu_ids=[0], \n",
    "    basedir='./data/HSI_Data/Hyperspectral_Project/HYPSO2/results', \n",
    "    epoch=100, \n",
    "    update_lr=5e-05, \n",
    "    meta_lr=5e-05, \n",
    "    n_way=1, \n",
    "    k_spt=2, \n",
    "    k_qry=5, \n",
    "    task_num=16, \n",
    "    update_step=5, \n",
    "    update_step_test=10\n",
    ")\n",
    "Cuda Acess: 1\n",
    "=> creating model 'hypersigma'\n",
    "load our vit fusion_new_v5 final models\n",
    "\n",
    "checkpoint = torch.load(pretrained, map_location='cpu')\n",
    "\n",
    "MSELoss()\n",
    "==> Resuming from checkpoint ./output/original_hypersigma_1e-4_spat-base_batch4_warmup_l2_epoch_1_complex_s3_8point_HYPSO2/hypersigma_gaussian/model_latest.pth..\n",
    "\n",
    "checkpoint = torch.load(resumePath or model_best_path)\n",
    "Number of parameter: 193.55M\n",
    "./data/HSI_Data/Hyperspectral_Project/HYPSO2/test_noise/Patch_Cases/Case5/test_8.mat\n",
    "./data/HSI_Data/Hyperspectral_Project/HYPSO2/test_noise/Patch_Cases/Case5/test_0.mat\n",
    "./data/HSI_Data/Hyperspectral_Project/HYPSO2/test_noise/Patch_Cases/Case5/test_6.mat\n",
    "./data/HSI_Data/Hyperspectral_Project/HYPSO2/test_noise/Patch_Cases/Case5/test_3.mat\n",
    "./data/HSI_Data/Hyperspectral_Project/HYPSO2/test_noise/Patch_Cases/Case5/test_5.mat\n",
    "./data/HSI_Data/Hyperspectral_Project/HYPSO2/test_noise/Patch_Cases/Case5/test_2.mat\n",
    "./data/HSI_Data/Hyperspectral_Project/HYPSO2/test_noise/Patch_Cases/Case5/test_7.mat\n",
    "./data/HSI_Data/Hyperspectral_Project/HYPSO2/test_noise/Patch_Cases/Case5/test_4.mat\n",
    "./data/HSI_Data/Hyperspectral_Project/HYPSO2/test_noise/Patch_Cases/Case5/test_1.mat\n",
    "Adjust Learning Rate => 1.0000e-04\n",
    "1727386755.7704296\n",
    "[i] Eval dataset ...\n",
    "./data/HSI_Data/Hyperspectral_Project/HYPSO2/test_noise/Patch_Cases/Case5/test_8.mat\n",
    "./data/HSI_Data/Hyperspectral_Project/HYPSO2/test_noise/Patch_Cases/Case5/test_0.mat\n",
    "0\n",
    "torch.Size([1, 120, 64, 64])\n",
    "./data/HSI_Data/Hyperspectral_Project/HYPSO2/test_noise/Patch_Cases/Case5/test_6.mat\n",
    "\n",
    "warnings.warn(\n",
    "./data/HSI_Data/Hyperspectral_Project/HYPSO2/test_noise/Patch_Cases/Case5/test_3.mat| Tot: 0ms | Loss: 4.6058e-03 | PSNR: 24.1270 | AVGPSNR: 24.127 1/9 \n",
    "1\n",
    "torch.Size([1, 120, 64, 64])\n",
    "./data/HSI_Data/Hyperspectral_Project/HYPSO2/test_noise/Patch_Cases/Case5/test_5.matot: 97ms | Loss: 4.0231e-03 | PSNR: 26.4288 | AVGPSNR: 25.277 2/9 \n",
    "2\n",
    "torch.Size([1, 120, 64, 64])\n",
    "./data/HSI_Data/Hyperspectral_Project/HYPSO2/test_noise/Patch_Cases/Case5/test_2.matot: 181ms | Loss: 3.6586e-03 | PSNR: 26.2393 | AVGPSNR: 25.598 3/9 \n",
    "3\n",
    "torch.Size([1, 120, 64, 64])\n",
    "./data/HSI_Data/Hyperspectral_Project/HYPSO2/test_noise/Patch_Cases/Case5/test_7.matot: 262ms | Loss: 3.5386e-03 | PSNR: 26.3787 | AVGPSNR: 25.793 4/9 \n",
    "4\n",
    "torch.Size([1, 120, 64, 64])\n",
    "./data/HSI_Data/Hyperspectral_Project/HYPSO2/test_noise/Patch_Cases/Case5/test_4.matot: 354ms | Loss: 3.5157e-03 | PSNR: 25.4158 | AVGPSNR: 25.717 5/9 \n",
    "5\n",
    "torch.Size([1, 120, 64, 64])\n",
    "./data/HSI_Data/Hyperspectral_Project/HYPSO2/test_noise/Patch_Cases/Case5/test_1.matTot: 456ms | Loss: 3.3134e-03 | PSNR: 27.3817 | AVGPSNR: 25.995 6/9 \n",
    "6\n",
    "torch.Size([1, 120, 64, 64])\n",
    "7[===========================================>.....................]  Step: 88ms | Tot: 545ms | Loss: 3.1914e-03 | PSNR: 26.9378 | AVGPSNR: 26.129 7/9 \n",
    "torch.Size([1, 120, 64, 64])\n",
    "8[==================================================>..............]  Step: 104ms | Tot: 649ms | Loss: 3.0727e-03 | PSNR: 27.4128 | AVGPSNR: 26.290 8/9 \n",
    "torch.Size([1, 120, 64, 64])\n",
    " [=========================================================>.......]  Step: 93ms | Tot: 743ms | Loss: 2.9807e-03 | PSNR: 27.4071 | AVGPSNR: 26.414 9/9 \n",
    "26.414331939999883 13.822076299706104 0.904122065688788 9.187853931398442 19.87596045703036\n",
    "26.414331939866347 0.002980694097156326 0.16035830229520798\n",
    "cost-time:  0.03674733638763428\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
